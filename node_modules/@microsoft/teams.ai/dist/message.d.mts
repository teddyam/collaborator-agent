import { Citation } from './citation.mjs';
import { FunctionCall } from './function.mjs';
import './schema.mjs';

type Message = UserMessage | ModelMessage | SystemMessage | FunctionMessage;
type UserMessage = {
    role: 'user';
    content: string | ContentPart[];
};
type ModelMessage = {
    role: 'model';
    audio?: MessageAudio;
    content?: string;
    context?: MessageContext;
    function_calls?: FunctionCall[];
};
type SystemMessage = {
    role: 'system';
    content: string;
};
type FunctionMessage = {
    role: 'function';
    content?: string;
    function_id: string;
};
type ContentPart = TextContentPart | ImageContentPart;
type TextContentPart = {
    type: 'text';
    text: string;
};
type ImageContentPart = {
    type: 'image_url';
    image_url: string;
};
/**
 * A representation of the additional context information available when Azure OpenAI chat extensions are involved
 * in the generation of a corresponding chat completions response. This context information is only populated when
 * using an Azure OpenAI request configured to use a matching extension.
 */
type MessageContext = {
    /**
     * The contextual information associated with the Azure chat extensions used for a chat completions request.
     * These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the
     * course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat
     * extensions.
     */
    citations?: Array<Citation>;
    /** The detected intent from the chat history, used to pass to the next turn to carry over the context. */
    intent?: string;
};
/**
 * If the audio output modality is requested, this object contains data about the
 * audio response from the model.
 */
type MessageAudio = {
    /**
     * Unique identifier for this audio response.
     */
    id: string;
    /**
     * Base64 encoded audio bytes generated by the model, in the format specified in
     * the request.
     */
    data: string;
    /**
     * The Unix timestamp (in seconds) for when this audio response will no longer be
     * accessible on the server for use in multi-turn conversations.
     */
    expires_at: number;
    /**
     * Transcript of the audio generated by the model.
     */
    transcript: string;
};

export type { ContentPart, FunctionMessage, ImageContentPart, Message, MessageAudio, MessageContext, ModelMessage, SystemMessage, TextContentPart, UserMessage };
