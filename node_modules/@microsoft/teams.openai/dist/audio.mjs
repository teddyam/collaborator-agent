import OpenAI, { toFile } from 'openai';
import { ConsoleLogger } from '@microsoft/teams.common/logging';

class OpenAIAudioModel {
  constructor(options) {
    this.options = options;
    this._log = options.logger || new ConsoleLogger(`@microsoft/teams.openai/${this.options.model}`);
    this._openai = new OpenAI({
      apiKey: options.apiKey,
      baseURL: options.baseUrl,
      organization: options.organization,
      project: options.project,
      defaultHeaders: options.headers,
      fetch: options.fetch,
      timeout: options.timeout
    });
  }
  _openai;
  _log;
  async audioToText(params) {
    try {
      const res = await this._openai.audio.transcriptions.create({
        file: await toFile(params.data, `temp.${params.type}`, { type: params.type }),
        model: this.options.model,
        language: params.lang,
        prompt: params.prompt
      });
      return res.text;
    } catch (err) {
      this._log.error(err);
      throw err;
    }
  }
  async textToAudio(params) {
    try {
      const res = await this._openai.audio.speech.create({
        response_format: params.type,
        model: this.options.model,
        voice: params.voice,
        input: params.text
      });
      return Buffer.from(await res.arrayBuffer());
    } catch (err) {
      this._log.error(err);
      throw err;
    }
  }
}

export { OpenAIAudioModel };
//# sourceMappingURL=audio.mjs.map
//# sourceMappingURL=audio.mjs.map