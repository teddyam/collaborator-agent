import OpenAI from 'openai';
import { Fetch } from 'openai/core';
import { IChatModel, Message, ChatSendOptions, ModelMessage } from '@microsoft/teams.ai';
import { ILogger } from '@microsoft/teams.common/logging';

type ChatCompletionCreateParams = Omit<OpenAI.ChatCompletionCreateParams, 'model' | 'messages' | 'stream'>;
type OpenAIChatModelOptions = {
    readonly model: (string & {}) | OpenAI.Chat.ChatModel;
    readonly apiKey?: string;
    readonly baseUrl?: string;
    readonly organization?: string;
    readonly project?: string;
    readonly headers?: {
        [key: string]: string;
    };
    readonly fetch?: Fetch;
    readonly timeout?: number;
    readonly requestOptions?: ChatCompletionCreateParams;
    readonly logger?: ILogger;
};
type AzureOpenAIChatModelOptions = OpenAIChatModelOptions & {
    /**
     * Defaults to process.env['OPENAI_API_VERSION'].
     */
    apiVersion?: string;
    /**
     * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`
     */
    endpoint?: string;
    /**
     * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),
     * which will be invoked on every request.
     */
    azureADTokenProvider?: () => Promise<string>;
};
declare class OpenAIChatModel implements IChatModel<ChatCompletionCreateParams> {
    readonly options: OpenAIChatModelOptions | AzureOpenAIChatModelOptions;
    private readonly _openai;
    private readonly _log;
    constructor(options: OpenAIChatModelOptions | AzureOpenAIChatModelOptions);
    send(input: Message, options?: ChatSendOptions<ChatCompletionCreateParams>): Promise<ModelMessage>;
}

export { type AzureOpenAIChatModelOptions, type ChatCompletionCreateParams, OpenAIChatModel, type OpenAIChatModelOptions };
