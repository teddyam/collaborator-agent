'use strict';

var OpenAI = require('openai');
var logging = require('@microsoft/teams.common/logging');

function _interopDefault (e) { return e && e.__esModule ? e : { default: e }; }

var OpenAI__default = /*#__PURE__*/_interopDefault(OpenAI);

class OpenAIAudioModel {
  constructor(options) {
    this.options = options;
    this._log = options.logger || new logging.ConsoleLogger(`@microsoft/teams.openai/${this.options.model}`);
    this._openai = new OpenAI__default.default({
      apiKey: options.apiKey,
      baseURL: options.baseUrl,
      organization: options.organization,
      project: options.project,
      defaultHeaders: options.headers,
      fetch: options.fetch,
      timeout: options.timeout
    });
  }
  _openai;
  _log;
  async audioToText(params) {
    try {
      const res = await this._openai.audio.transcriptions.create({
        file: await OpenAI.toFile(params.data, `temp.${params.type}`, { type: params.type }),
        model: this.options.model,
        language: params.lang,
        prompt: params.prompt
      });
      return res.text;
    } catch (err) {
      this._log.error(err);
      throw err;
    }
  }
  async textToAudio(params) {
    try {
      const res = await this._openai.audio.speech.create({
        response_format: params.type,
        model: this.options.model,
        voice: params.voice,
        input: params.text
      });
      return Buffer.from(await res.arrayBuffer());
    } catch (err) {
      this._log.error(err);
      throw err;
    }
  }
}

exports.OpenAIAudioModel = OpenAIAudioModel;
//# sourceMappingURL=audio.js.map
//# sourceMappingURL=audio.js.map